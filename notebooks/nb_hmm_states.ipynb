{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm -it --platform linux/amd64 -p 8888:8888 -v \"/Users/em/code/DeepASM/notebooks:/notebooks\" us-east1-docker.pkg.dev/hmh-em-deepasm/docker-repo/python:${SHORT_SHA} jupyter notebook --ip=0.0.0.0 --no-browser --allow-root --NotebookApp.notebook_dir=/notebooks\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "rs = check_random_state(546)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP authorization\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"hmh-em-deepasm-404a5540e8c3.json\"\n",
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "PROJECT_ID = \"hmh-em-deepasm\"\n",
    "BQ_ML_DATASET = \"hg19_250_ml_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_data = {'train': {'samples': ['gm12878',\n",
    "                                  'CD14',\n",
    "                                  'fibroblast',\n",
    "                                  'A549',\n",
    "                                  'spleen_female_adult',\n",
    "                                  'HeLa_S3']},\n",
    "            'validation': {'samples': ['mammary_epithelial',\n",
    "                                       'sk_n_sh',\n",
    "                                       'CD34']},\n",
    "            'test': {'samples': ['HepG2',\n",
    "                                 'righ_lobe_liver',\n",
    "                                 't_cell_male_adult']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'train'\n",
    "samples = dic_data[dataset_name]    \n",
    "# Reformat samples for BQ\n",
    "quoted_samples = \",\".join([f\"'{sample}'\" for sample in samples['samples']])\n",
    "\n",
    "# Query\n",
    "query = f\"SELECT * FROM {PROJECT_ID}.{BQ_ML_DATASET}.tabular WHERE sample IN ({quoted_samples})\"\n",
    "\n",
    "# Execute Query and store as DF\n",
    "df = bq_client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = np.array(np.concatenate(df['directional_cpg_frac'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_hmm(sequence):\n",
    "    \"\"\"\n",
    "    Prepares a sequence of data for processing with a Hidden Markov Model (HMM).\n",
    "\n",
    "    This function ensures the input sequence is in a 2D NumPy array format required by HMM processing routines, handling both single-dimensional sequences (interpreting them as a sequence of scalar observations) and two-dimensional sequences (interpreting them as a sequence of vector observations). It also calculates the length of the sequence, which is necessary for some HMM algorithms.\n",
    "\n",
    "    Parameters:\n",
    "    - sequence (np.ndarray): The input sequence to be processed. This can be either a 1D array of scalar observations or a 2D array of vector observations, where each row represents a timestep.\n",
    "\n",
    "    Returns:\n",
    "    - sequence (np.ndarray): The input sequence reshaped into a 2D NumPy array format, with individual observations along rows.\n",
    "    - lengths (list of int): A list containing a single integer, which is the length of the input sequence. This is used by HMM algorithms that require the lengths of sequences being processed.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the input `sequence` has more than two dimensions, indicating it's not in an acceptable format for HMM processing.\n",
    "    \"\"\"\n",
    "\n",
    "    if sequence.ndim == 1:\n",
    "        sequence = np.atleast_2d(sequence).T\n",
    "    elif sequence.ndim > 2:\n",
    "        raise ValueError(\n",
    "            \"Sequence must be 1D (for single float sequence) or 2D (for sequence of vectors)\"\n",
    "        )\n",
    "\n",
    "    # Determine the length of the sequence dynamically\n",
    "    sequence_length = sequence.shape[0]\n",
    "\n",
    "    # For a single sequence, the lengths list contains just one element: the sequence length\n",
    "    lengths = [sequence_length]\n",
    "\n",
    "    return sequence, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data, lengths = prepare_data_for_hmm(all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: 4205335.523713576 is not greater than 4205335.52418127. Delta is -0.00046769436448812485\n",
      "Model is not converging.  Current: 4205335.525052782 is not greater than 4205335.525366359. Delta is -0.00031357724219560623\n",
      "Model is not converging.  Current: 4205335.526135785 is not greater than 4205335.526223325. Delta is -8.754059672355652e-05\n"
     ]
    }
   ],
   "source": [
    "aic = []\n",
    "bic = []\n",
    "lls = []\n",
    "ns = [2, 3, 4, 5, 6]\n",
    "for n in ns:\n",
    "    print(f\"Number of states: {n}\")\n",
    "    best_ll = None\n",
    "    best_model = None\n",
    "    for i in range(10):\n",
    "        h = GaussianHMM(n, n_iter=200, tol=1e-4, random_state=rs)\n",
    "        h.fit(reshaped_data, lengths)\n",
    "        score = h.score(reshaped_data)\n",
    "        if not best_ll or best_ll < best_ll:\n",
    "            best_ll = score\n",
    "            best_model = h\n",
    "    aic.append(best_model.aic(reshaped_data))\n",
    "    bic.append(best_model.bic(reshaped_data))\n",
    "    lls.append(best_model.score(reshaped_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ln1 = ax.plot(ns, aic, label=\"AIC\", color=\"blue\", marker=\"o\")\n",
    "ln2 = ax.plot(ns, bic, label=\"BIC\", color=\"green\", marker=\"o\")\n",
    "ax2 = ax.twinx()\n",
    "ln3 = ax2.plot(ns, lls, label=\"LL\", color=\"orange\", marker=\"o\")\n",
    "\n",
    "ax.legend(handles=ax.lines + ax2.lines)\n",
    "ax.set_title(\"Using AIC/BIC for Model Selection\")\n",
    "ax.set_ylabel(\"Criterion Value (lower is better)\")\n",
    "ax2.set_ylabel(\"LL (higher is better)\")\n",
    "ax.set_xlabel(\"Number of HMM Components\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_model.transmat_ is defined and contains the transition matrix you want to plot\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the transition matrix\n",
    "cax = ax.imshow(best_model.transmat_, aspect='auto')\n",
    "\n",
    "# Create a colorbar with a reference to the imshow plot\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Transition Matrix')\n",
    "ax.set_xlabel('State To')\n",
    "ax.set_ylabel('State From')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Example Gaussian parameters for 5 states\n",
    "means = np.round(best_model.means_.flatten(),3)  # [1, 3, 5, 7, 9]\n",
    "covariances = np.round(best_model.covars_.flatten(),3) #[0.5, 0.2, 1.0, 0.3, 0.7]  # Variance in this case\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Value range for x-axis\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "\n",
    "# Plot each Gaussian\n",
    "for mean, cov in zip(means, covariances):\n",
    "    plt.plot(x, norm.pdf(x, mean, np.sqrt(cov)), label=f'Mean: {mean}, Var: {cov}')\n",
    "\n",
    "plt.title('Gaussian Distributions of HMM States')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
